{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/gTUu5C103SRTZ19Pt1eb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmari038/Language-Translator/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install spacy\n",
        "#!pip install collections"
      ],
      "metadata": {
        "id": "MmcSj7k0iOb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "xqCfxMAWw9R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import random_split\n",
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter, OrderedDict"
      ],
      "metadata": {
        "id": "oiDcQWEB7eTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Cuda activated\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "dataset = 'https://raw.githubusercontent.com/cmari038/Language-Translator/main/data.csv'\n",
        "data = pd.read_csv(dataset)\n",
        "\n",
        "#spacy.load('en_core_web_sm')\n",
        "#spacy.load('es_core_news_sm')\n",
        "\n",
        "# processing data\n",
        "\n",
        "english_tokenizer = get_tokenizer('spacy', language = 'en_core_web_sm')\n",
        "spanish_tokenizer = get_tokenizer('spacy', language= 'es_core_news_sm')\n",
        "\n",
        "#print(data)\n",
        "\n",
        "train = data.sample(frac=0.7)\n",
        "validate = data.drop(train.index).sample(frac=0.1)\n",
        "test = data.drop(validate.index)\n",
        "\n",
        "counter1 = Counter()\n",
        "counter2 = Counter()\n",
        "\n",
        "for sentence in train['english']:\n",
        "  counter1.update(english_tokenizer(sentence))\n",
        "\n",
        "for sentence in train['spanish']:\n",
        "  counter2.update(spanish_tokenizer(sentence))\n",
        "\n",
        "en_dict = OrderedDict(counter1.most_common())\n",
        "es_dict = OrderedDict(counter2.most_common())\n",
        "\n",
        "vocab1 = vocab(en_dict, specials = ['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "vocab2 = vocab(es_dict, specials = ['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "\n",
        "vocab1.set_default_index(vocab1['<unk>'])\n",
        "vocab2.set_default_index(vocab2['<unk>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV0KWu9MilTU",
        "outputId": "e3674af9-bdfe-4311-b862-53f86a4a0006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda activated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTokens(df, en_tokenizer, es_tokenizer, lang):\n",
        "  if lang == \"english\":\n",
        "    en_tokens = []\n",
        "\n",
        "    for token in en_tokenizer(df):\n",
        "      en_tokens.append(token)\n",
        "\n",
        "    en_tokens = ['<sos>'] + en_tokens + ['<eos>']\n",
        "\n",
        "    return en_tokens\n",
        "\n",
        "  else:\n",
        "    es_tokens = []\n",
        "\n",
        "    for token in es_tokenizer(df):\n",
        "        es_tokens.append(token)\n",
        "\n",
        "    es_tokens = ['sos'] + es_tokens + ['<eos>']\n",
        "\n",
        "    return es_tokens\n",
        "\n",
        "\n",
        "#token_dict = {\"en_tokenizer\": english_tokenizer, \"es_tokenizer\": spanish_tokenizer}\n",
        "#train = train.apply(map(lambda col: col.map(getTokens)))\n",
        "en_tokens = []\n",
        "es_tokens = []\n",
        "\n",
        "for element in train['english']:\n",
        "  tmp1 = getTokens(element, english_tokenizer, spanish_tokenizer, \"english\")\n",
        "  en_tokens.append(tmp1)\n",
        "\n",
        "for element in train[\"spanish\"]:\n",
        "  tmp2 = getTokens(element, english_tokenizer, spanish_tokenizer, \"spanish\")\n",
        "  es_tokens.append(tmp2)\n",
        "\n",
        "train['en_tokens'] = en_tokens\n",
        "train['es_tokens'] = es_tokens\n",
        "\n",
        "#print(train['en_tokens'])"
      ],
      "metadata": {
        "id": "32pkZX7Z7RWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getIndices(df, en_vocab, es_vocab, lang):\n",
        "  if lang == \"english\":\n",
        "    en_indices = []\n",
        "\n",
        "    for word in df:\n",
        "      en_indices.append(en_vocab[word])\n",
        "\n",
        "    return en_indices\n",
        "\n",
        "  else:\n",
        "    es_indices = []\n",
        "\n",
        "    for word in df:\n",
        "        es_indices.append(es_vocab[word])\n",
        "\n",
        "    return es_indices\n",
        "\n",
        "en_indices = []\n",
        "es_indices = []\n",
        "\n",
        "for element in train[\"en_tokens\"]:\n",
        "  tmp1 = getIndices(element, vocab1, vocab2, \"english\")\n",
        "  en_indices.append(tmp1)\n",
        "\n",
        "for element in train[\"es_tokens\"]:\n",
        "  tmp1 = getIndices(element, vocab1, vocab2, \"spanish\")\n",
        "  es_indices.append(tmp1)\n",
        "\n",
        "train['es_indices'] = es_indices\n",
        "train['en_indices']= en_indices\n",
        "\n",
        "#en_tensor = []\n",
        "#es_tensor = []\n",
        "\n",
        "\"\"\"\n",
        "print(train['en_indices'])\n",
        "\n",
        "for series in train['en_indices']:\n",
        "  en_tensor.append(torch.tensor(series, dtype=torch.long))\n",
        "\n",
        "for series in train['es_indices']:\n",
        "  es_tensor.append(torch.tensor(series, dtype=torch.long))\n",
        "\n",
        "train['en_indices'] = en_tensor\n",
        "train['es_indices'] = es_tensor\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-xUWIEhSSD7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1e3523bc-680a-4438-8b62-b31c317feca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nprint(train['en_indices'])\\n\\nfor series in train['en_indices']:\\n  en_tensor.append(torch.tensor(series, dtype=torch.long))\\n\\nfor series in train['es_indices']:\\n  es_tensor.append(torch.tensor(series, dtype=torch.long))\\n\\ntrain['en_indices'] = en_tensor\\ntrain['es_indices'] = es_tensor\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(train['es_indices'])"
      ],
      "metadata": {
        "id": "sEWYpiYjY6bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "class TensorSet(Dataset):\n",
        "  def __init__(self, data, en_tokenizer, es_tokenizer, en_vocab, es_vocab):\n",
        "    self.data = data\n",
        "    self.en_tokenizer = en_tokenizer\n",
        "    self.es_tokenizer = es_tokenizer\n",
        "    self.en_vocab = en_vocab\n",
        "    self.es_vocab = es_vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    english = self.data.iloc[index]['english']\n",
        "    spanish = self.data.iloc[index]['spanish']\n",
        "    en_indices = []\n",
        "    es_indices = []\n",
        "\n",
        "    en_tokens = self.en_tokenizer(english)\n",
        "    es_tokens = self.es_tokenizer(spanish)\n",
        "\n",
        "    for token in en_tokens:\n",
        "      en_indices.append(self.en_vocab[token])\n",
        "\n",
        "    for token in es_tokens:\n",
        "      es_indices.append(self.es_vocab[token])\n",
        "\n",
        "    en_tensor = torch.tensor([self.en_vocab['<sos>']] + en_indices + [self.en_vocab['<eos>']], dtype=torch.long)\n",
        "    es_tensor = torch.tensor([self.en_vocab['<sos>']] + es_indices + [self.en_vocab['<eos>']], dtype=torch.long)\n",
        "\n",
        "    return en_tensor, es_tensor\n",
        "  \"\"\"\n",
        "\n",
        "class TensorSet(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return torch.tensor(self.df['en_indices'].iloc[index], dtype=torch.long), torch.tensor(self.df['es_indices'].iloc[index], dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "  # used for making sure sequences are similar lengths by adding tokens to pad out the length\n",
        "  en_batch = []\n",
        "  es_batch = []\n",
        "  for en_sample, es_sample in batch:\n",
        "    en_batch.append(en_sample)\n",
        "    es_batch.append(es_sample)\n",
        "\n",
        "  en_batch = pad_sequence(en_batch, padding_value=vocab1['<pad>'])\n",
        "  es_batch = pad_sequence(es_batch, padding_value=vocab2['<pad>'])\n",
        "\n",
        "  return en_batch, es_batch\n",
        "\n",
        "#tensorSet = TensorSet(train, english_tokenizer, spanish_tokenizer, vocab1, vocab2)\n",
        "tensorSet = TensorSet(train)\n",
        "batch_size = 128\n",
        "dataLoad = DataLoader(tensorSet, shuffle=True, collate_fn=collate_fn, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "Zh8-rGf-GpvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Encoder(nn.Module):\n",
        "    def __init__(self, input, embedding_dimension, hidden_dimension, layers, dropout_p=0.5):\n",
        "        super(RNN_Encoder, self).__init__()\n",
        "        self.hidden_dimension = hidden_dimension\n",
        "        self.layers = layers\n",
        "        self.embed = nn.Embedding(input, embedding_dimension)\n",
        "        self.gru = nn.LSTM(embedding_dimension, hidden_dimension, layers, dropout=dropout_p)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, english):\n",
        "        embedded = self.dropout(self.embed(english))\n",
        "        output, (hidden, cell) = self.gru(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, output, embedding_dimension, hidden_dimension, layers, dropout_p=0.5):\n",
        "      super(RNN_Decoder, self).__init__()\n",
        "      self.output = output\n",
        "      self.hidden_dimension = hidden_dimension\n",
        "      self.layers = layers\n",
        "      self.embed = nn.Embedding(output, hidden_dimension)\n",
        "      self.gru = nn.LSTM(embedding_dimension, hidden_dimension, layers, dropout=dropout_p)\n",
        "      self.fc_out = nn.Linear(hidden_dimension, output)\n",
        "      self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "      input = input.unsqueeze(0)\n",
        "      embedded = self.dropout(self.embed(input))\n",
        "      output, (hidden, cell) = self.gru(embedded, (hidden, cell))\n",
        "      prediction = self.fc_out(output.squeeze(0))\n",
        "      #output = self.embed(input)\n",
        "      #output = functional.relu(output)\n",
        "      #output, hidden = self.gru(output, hidden)\n",
        "      return prediction, hidden, cell\n",
        "\n",
        "class Sequence(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "      super(Sequence, self).__init__()\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.device = device\n",
        "\n",
        "    def forward(self, english, spanish, teacher_forcing_ratio):\n",
        "      \"\"\"\n",
        "      batch_length = english.size(0)\n",
        "      highest_es_length = spanish.size(1)\n",
        "      en_vocab_length = self.decoder.output.out_features\n",
        "      outputs = torch.zeros(batch_length, highest_es_length, en_vocab_length).to(self.device)\n",
        "      encoder_outputs, hidden = self.encoder(english, english_length)\n",
        "      decoder_input = torch.tensor([vocab2['<sos>']] * batch_length).to(self.device)\n",
        "\n",
        "      for i in range(highest_es_length):\n",
        "        output, hidden = self.decoder(decoder_input, hidden)\n",
        "        outputs[:, i, :] = output\n",
        "        teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "        top1 = output.argmax(1)\n",
        "        decoder_input = spanish[:, i] if teacher_force else top1\n",
        "      \"\"\"\n",
        "\n",
        "      batch_size = spanish.shape[1]\n",
        "      es_length = spanish.shape[0]\n",
        "      es_vocab_size = self.decoder.output\n",
        "      outputs = torch.zeros(es_length, batch_size,es_vocab_size).to(self.device)\n",
        "      hidden, cell = self.encoder(english)\n",
        "      input = spanish[0,:]\n",
        "\n",
        "      for i in range(1, es_length):\n",
        "        output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "        outputs[i] = output\n",
        "        teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "        top1 = output.argmax(1)\n",
        "        decoder_input = spanish[i] if teacher_force else top1\n",
        "\n",
        "      return outputs\n",
        "\n",
        "encoder = RNN_Encoder(len(vocab1), 256, 100, 2)\n",
        "decoder = RNN_Decoder(len(vocab2), 256, 100, 2)\n",
        "RNN_model = Sequence(encoder, decoder, device).to(device)"
      ],
      "metadata": {
        "id": "o-Bcb9Nspvh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab2['<pad>'])\n",
        "optimizer = torch.optim.Adam(RNN_model.parameters())\n",
        "\n",
        "def train(RNN_model, dataLoad, criterion, optimizer, device, epochs, teacher_forcing_ratio, clip):\n",
        "  RNN_model.train()\n",
        "  for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    for english, spanish in dataLoad: # iterate in batches through dataloader\n",
        "      english = english.to(device)\n",
        "      spanish = spanish.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = RNN_model(english, spanish, teacher_forcing_ratio)\n",
        "      output = output[1:].view(-1, output.shape[-1])\n",
        "      spanish = spanish[1:].view(-1)\n",
        "\n",
        "      loss = criterion(output, spanish)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(RNN_model.parameters(),clip)\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "train(RNN_model, dataLoad, criterion, optimizer, device, 5, 0.5, 1.0)"
      ],
      "metadata": {
        "id": "zVJg6uIts0-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "b2df411b-82b6-40ca-f26e-53e5dd1aa1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-42ed331766ea>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-42ed331766ea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(RNN_model, dataLoad, criterion, optimizer, device, epochs, teacher_forcing_ratio, clip)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translation(model, input, vocab1, vocab2, device):\n",
        "\n",
        "  model.eval()\n",
        "  #tokens = english_tokenizer(input)\n",
        "  #indices = []\n",
        "  \"\"\"for token in tokens:\n",
        "      indices.append(vocab1[token])\n",
        "  input_tensor = torch.tensor([vocab1['<sos>']] + indices + [vocab1['<eos>']], dtype=torch.long) \"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    tokens = getTokens(input, english_tokenizer, spanish_tokenizer, \"english\")\n",
        "    indices = getIndices(tokens, vocab1, vocab2, \"english\")\n",
        "    tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(-1).to(device)\n",
        "    hidden, cell = model.encoder(tensor)\n",
        "    spanish = [vocab2['<sos>']]\n",
        "\n",
        "    \"\"\"encoder_output, hidden = model.encoder(tensor, len(tokens))\n",
        "    spanish_vocab = {i: word for word, i in spanish_vocab.items()}\n",
        "    decoder_input = torch.tensor([vocab2['<sos>']]).to(device)\n",
        "    spanish = [] \"\"\"\n",
        "\n",
        "    for i in range(50):\n",
        "        tensorInput = torch.tensor([spanish[-1]], dtype=torch.long).to(device)\n",
        "        decoder_output, hidden, cell = model.decoder(tensorInput, hidden, cell)\n",
        "        top1 = decoder_output.argmax(-1).item()\n",
        "        if top1 == vocab2['<eos>']:\n",
        "          break\n",
        "        spanish.append(top1)\n",
        "        decoder_input = torch.tensor([top1]).to(device)\n",
        "    tokens = vocab2.lookup_tokens(spanish)\n",
        "  return tokens\n",
        "\n",
        "\n",
        "#train(RNN_model, dataLoad, criterion, optimizer, device, 10, 0.5)\n",
        "sentence = \"Hello there\"\n",
        "translated_sentence = translation(RNN_model, sentence, vocab1, vocab2, device)\n",
        "print(translated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxm8K3KnVwJ7",
        "outputId": "d06a8cb2-6171-4a40-b0d1-9371bdd97c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<sos>', 'Tom']\n"
          ]
        }
      ]
    }
  ]
}